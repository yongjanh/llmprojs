# ==============================================================================
# è¯´æ˜ï¼šæœ¬æ–‡ä»¶é‡‡ç”¨å¾ªåºæ¸è¿›çš„æ–¹å¼ï¼Œæ¼”ç¤ºå¦‚ä½•å¯¹ RAG ç³»ç»Ÿè¿›è¡Œè‡ªåŠ¨åŒ–è¯„ä¼° (Ragas)
# ==============================================================================
# ä»é›¶å¼€å§‹æ„å»ºè¯„ä¼°ç›´è§‰ï¼Œé€æ­¥å¼•å…¥ä¸“ä¸šæ¡†æ¶ Ragasï¼Œæœ€ç»ˆå®ç°é€‚é…ä¸­æ–‡åœºæ™¯çš„å…¨ç»´åº¦è¯„ä¼°ã€‚
#
# ã€æ ¸å¿ƒç›®æ ‡ã€‘
# è®© RAG å¼€å‘ä»"å‡­æ„Ÿè§‰"å˜ä¸º"æ•°æ®é©±åŠ¨"ï¼Œé€šè¿‡é‡åŒ–æŒ‡æ ‡æŒç»­ä¼˜åŒ–ç³»ç»Ÿè´¨é‡ã€‚
#
# ã€ä¸ºä»€ä¹ˆéœ€è¦è¯„ä¼°ï¼Ÿã€‘
# âŒ æ²¡æœ‰è¯„ä¼°ï¼šä¸çŸ¥é“ RAG ç³»ç»Ÿå¥½ä¸å¥½ï¼Œåªèƒ½é äººå·¥æµ‹è¯•
# âœ“ æœ‰äº†è¯„ä¼°ï¼šå®¢è§‚é‡åŒ–è´¨é‡ï¼Œå¿«é€Ÿå‘ç°é—®é¢˜ï¼ŒæŒ‡å¯¼ä¼˜åŒ–æ–¹å‘
#
# ã€è„šæœ¬æ‰§è¡Œæ­¥éª¤ã€‘
# æ­¥éª¤ 1ï¼šæ‰‹åŠ¨ RAG è¯„ä¼°ä½“éªŒ
#   - è¿è¡ŒçœŸå® RAG æŸ¥è¯¢ï¼Œç›´è§‚æ„Ÿå—æ•ˆæœ
#   - ç¼–å†™ç®€å•çš„ LLM è£åˆ¤å‡½æ•°ï¼Œå»ºç«‹"è®© AI è¯„æµ‹ AI"çš„ç›´è§‰
#
# æ­¥éª¤ 2ï¼šåˆè¯† Ragas æ¡†æ¶ - ç”Ÿæˆè´¨é‡
#   - å¼•å…¥ Ragas åº“ï¼Œå…³æ³¨ `Answer Correctness`ï¼ˆå›ç­”æ­£ç¡®æ€§ï¼‰
#   - ä½¿ç”¨é»˜è®¤è‹±æ–‡ Prompt è¿›è¡Œåˆæ­¥æ‰“åˆ†
#
# æ­¥éª¤ 3ï¼šè¿›é˜¶ Ragas è¯„ä¼° - æ£€ç´¢è´¨é‡
#   - å¼•å…¥ `Context Recall`ï¼ˆå¬å›ç‡ï¼‰å’Œ `Context Precision`ï¼ˆç²¾ç¡®åº¦ï¼‰
#   - ç†è§£æ£€ç´¢ç¯èŠ‚çš„ä¸¤ä¸ªæ ¸å¿ƒç—›ç‚¹ï¼šä¸ä»…è¦"æ‰¾å¾—åˆ°"ï¼Œè¿˜è¦"æ’å¾—å‡†"
#
# æ­¥éª¤ 4ï¼šåŸç†æ·±åº¦è§£æ
#   - è¯¦ç»†è§£æ Ragas æ ¸å¿ƒæŒ‡æ ‡çš„è®¡ç®—é€»è¾‘
#   - é€šè¿‡å…·ä½“æ¡ˆä¾‹ç†è§£è¯„åˆ†æœºåˆ¶
#
# æ­¥éª¤ 5ï¼šç”Ÿäº§çº§ä¼˜åŒ– - ä¸­æ–‡é€‚é…
#   - é’ˆå¯¹é»˜è®¤ Prompt åœ¨ä¸­æ–‡åœºæ™¯ä¸‹çš„é—®é¢˜ï¼ŒåŠ è½½è‡ªå®šä¹‰ä¸­æ–‡æ¨¡æ¿
#   - æ‰§è¡Œå…¨ç»´åº¦è¯„ä¼°ï¼ˆGeneration + Retrievalï¼‰ï¼Œè·å¾—å¯ä¿¡è¯„æµ‹æŠ¥å‘Š
#
# ã€Ragas æ ¸å¿ƒæŒ‡æ ‡ã€‘
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ æŒ‡æ ‡              â”‚ è¯„ä¼°å†…å®¹                             â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ Answer Correctnessâ”‚ å›ç­”æ˜¯å¦æ­£ç¡®ï¼ˆè¯­ä¹‰ + äº‹å®ï¼‰          â”‚
# â”‚ Context Recall    â”‚ æ£€ç´¢æ˜¯å¦æ‰¾åˆ°äº†æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼ˆå¬å›ç‡ï¼‰ â”‚
# â”‚ Context Precision â”‚ æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§å’Œæ’åºè´¨é‡ï¼ˆç²¾ç¡®åº¦ï¼‰ â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# ã€Ragas çš„æ ¸å¿ƒæœºåˆ¶ã€‘
# âš ï¸ å…³é”®æŠ€æœ¯ç»†èŠ‚ï¼šRagas ä¸æ˜¯ç›´æ¥å¯¹æ¯”æ–‡æœ¬ï¼Œè€Œæ˜¯å…ˆç”¨ LLM å°†æ–‡æœ¬åˆ†è§£ä¸º
# **è§‚ç‚¹åºåˆ—ï¼ˆstatements/claimsï¼‰**ï¼Œç„¶ååœ¨è§‚ç‚¹å±‚é¢è¿›è¡Œå¯¹æ¯”å’Œåˆ¤æ–­ã€‚
#
# ä¾‹å¦‚ï¼š
# - åŸæ–‡ï¼š"å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜ï¼Œè´Ÿè´£è¯¾ç¨‹ç ”å‘"
# - è§‚ç‚¹åºåˆ—ï¼š["å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜", "å¼ ä¼Ÿè´Ÿè´£è¯¾ç¨‹ç ”å‘"]
#
# è¿™æ ·åšçš„å¥½å¤„ï¼š
# âœ“ é¿å…è¢«è¡¨è¿°æ–¹å¼è¯¯å¯¼ï¼ˆåŒä¸€äº‹å®å¯èƒ½æœ‰ä¸åŒè¡¨è¿°ï¼‰
# âœ“ åŸå­åŒ–è¯„ä¼°ï¼Œæ›´ç²¾ç¡®åœ°å®šä½é—®é¢˜
# âœ“ æ”¯æŒå¤æ‚æ–‡æœ¬çš„å¤šç»´åº¦è¯„ä¼°
# ==============================================================================

from chatbot import rag, llm
from config.load_key import load_key

# é…ç½® tqdm è¿›åº¦æ¡
from tqdm.cli import tqdm as tqdm_cli
import tqdm.auto
tqdm.auto.tqdm = tqdm_cli


# ==============================================================================
# æ­¥éª¤ 1: æ‰‹åŠ¨ RAG è¯„ä¼°ä½“éªŒ
# ==============================================================================

def demo_manual_rag_evaluation():
    """
    æ¼”ç¤ºæ‰‹åŠ¨ RAG è¯„ä¼°ï¼šç›´è§‚æ„Ÿå— RAG ç³»ç»Ÿçš„æ•ˆæœã€‚
    
    ã€æ ¸å¿ƒæ€æƒ³ã€‘
    åœ¨å¼•å…¥ä¸“ä¸šæ¡†æ¶å‰ï¼Œå…ˆæ‰‹åŠ¨è¿è¡Œ RAG æŸ¥è¯¢ï¼Œå»ºç«‹åŸºæœ¬ç›´è§‰ã€‚
    
    ã€è¯„ä¼°ç»´åº¦ã€‘
    1. å›ç­”è´¨é‡ï¼šæ˜¯å¦æœ‰æ•ˆå›ç­”äº†é—®é¢˜ï¼Ÿ
    2. æ£€ç´¢è´¨é‡ï¼šå‚è€ƒä¿¡æ¯æ˜¯å¦æœ‰ç”¨ï¼Ÿ
    
    ã€å…³é”®å‘ç°ã€‘
    é€šè¿‡æ‰‹åŠ¨è¯„ä¼°ï¼Œæˆ‘ä»¬ä¼šå‘ç°ï¼š
    - RAG çš„æ•ˆæœå—æ£€ç´¢è´¨é‡å½±å“å·¨å¤§
    - äººå·¥è¯„ä¼°è€—æ—¶ä¸”ä¸»è§‚
    - æ€¥éœ€è‡ªåŠ¨åŒ–ã€å®¢è§‚çš„è¯„ä¼°æ–¹æ³•
    """
    print("\n" + "="*60)
    print("  æ­¥éª¤ 1: æ‰‹åŠ¨ RAG è¯„ä¼°ä½“éªŒ")
    print("="*60)
    
    # åˆ›å»ºæŸ¥è¯¢å¼•æ“
    query_engine = rag.create_query_engine(rag.load_index())
    
    # æå‡ºé—®é¢˜
    question = 'å¼ ä¼Ÿæ˜¯å“ªä¸ªéƒ¨é—¨çš„'
    print(f"\nğŸ’¬ æé—®ï¼š{question}")
    
    # è·å–å›ç­”
    response = query_engine.query(question)
    print('\nğŸ¤– å›ç­”ï¼š', end='')
    response.print_response_stream()
    
    # è·å–å®Œæ•´å›ç­”æ–‡æœ¬ï¼ˆæµå¼å“åº”åéœ€è¦ç”¨ get_response() æ–¹æ³•ï¼‰
    answer_text = response.get_response().response
    
    # è·å–å‚è€ƒä¿¡æ¯
    contexts = [node.get_content() for node in response.source_nodes]
    print('\n\nğŸ“š å‚è€ƒä¿¡æ¯ï¼š')
    for i, context in enumerate(contexts, 1):
        print(f"  [{i}] {context[:100]}...")
    
    print("\nğŸ’¡ è§‚å¯Ÿï¼šå‚è€ƒä¿¡æ¯ä¸­å¹¶æ²¡æœ‰å¼ ä¼Ÿçš„ä¿¡æ¯ï¼Œå¯¼è‡´å›ç­”è´¨é‡ä¸ä½³ã€‚")
    
    # ç¼–å†™ç®€å•çš„ LLM è£åˆ¤å‡½æ•°
    print("\n" + "-"*60)
    print("  ç¼–å†™ç®€å•çš„ LLM è£åˆ¤å‡½æ•°")
    print("-"*60)

    def test_answer(question, answer):
        """ç®€å•çš„å›ç­”è´¨é‡è¯„ä¼°å‡½æ•°"""
        prompt = (
            "ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•äººå‘˜ã€‚\n"
            "ä½ éœ€è¦æ£€æµ‹ä¸‹é¢çš„è¿™æ®µå›ç­”æ˜¯å¦æœ‰æ•ˆå›ç­”äº†ç”¨æˆ·çš„é—®é¢˜ã€‚\n"
            "å›å¤åªèƒ½æ˜¯ï¼šæœ‰æ•ˆå›ç­” æˆ–è€… æ— æ•ˆå›ç­”ã€‚è¯·å‹¿ç»™å‡ºå…¶ä»–ä¿¡æ¯ã€‚\n"
            "------\n"
            f"å›ç­”æ˜¯ {answer}\n"
            "------\n"
            f"é—®é¢˜æ˜¯ï¼š {question}\n"
        )
        return llm.invoke(prompt, model_name="qwen-max")

    def test_contexts(question, contexts):
        """ç®€å•çš„æ£€ç´¢è´¨é‡è¯„ä¼°å‡½æ•°"""
        prompt = (
            "ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•äººå‘˜ã€‚\n"
            "ä½ éœ€è¦æ£€æµ‹ä¸‹é¢çš„è¿™äº›å‚è€ƒèµ„æ–™æ˜¯å¦èƒ½å¯¹å›ç­”é—®é¢˜æœ‰å¸®åŠ©ã€‚\n"
            "å›å¤åªèƒ½æ˜¯ï¼šå‚è€ƒä¿¡æ¯æœ‰ç”¨ æˆ–è€… å‚è€ƒä¿¡æ¯æ— ç”¨ã€‚è¯·å‹¿ç»™å‡ºå…¶ä»–ä¿¡æ¯ã€‚\n"
            "------\n"
            f"å‚è€ƒèµ„æ–™æ˜¯ {contexts}\n"
            "------\n"
            f"é—®é¢˜æ˜¯ï¼š {question}\n"
        )
        return llm.invoke(prompt, model_name="qwen-max")
    
    # è¯„ä¼°å›ç­”
    print(f"\nâœ… å›ç­”è´¨é‡è¯„ä¼°ï¼š{test_answer(question, answer_text)}")
    
    # è¯„ä¼°æ£€ç´¢
    print(f"âœ… æ£€ç´¢è´¨é‡è¯„ä¼°ï¼š{test_contexts(question, contexts)}")
    
    print("\nğŸ’¡ è§‚å¯Ÿï¼šé€šè¿‡ç®€å•çš„ LLM è£åˆ¤ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªåŠ¨åŒ–è¯„ä¼°ï¼Œä½†è¿˜ä¸å¤Ÿä¸“ä¸šã€‚")


# ==============================================================================
# æ­¥éª¤ 2: åˆè¯† Ragas æ¡†æ¶ - ç”Ÿæˆè´¨é‡è¯„ä¼°
# ==============================================================================

def demo_ragas_answer_correctness():
    """
    æ¼”ç¤º Ragas æ¡†æ¶çš„ Answer Correctness æŒ‡æ ‡ã€‚
    
    ã€æ ¸å¿ƒæ€æƒ³ã€‘
    ä½¿ç”¨ä¸“ä¸šæ¡†æ¶ Ragas è¯„ä¼°å›ç­”çš„æ­£ç¡®æ€§ï¼ŒåŒ…æ‹¬è¯­ä¹‰ç›¸ä¼¼åº¦å’Œäº‹å®å‡†ç¡®åº¦ã€‚
    
    ã€Answer Correctness è®¡ç®—åŸç†ã€‘
    1. è¯­ä¹‰ç›¸ä¼¼åº¦ï¼šé€šè¿‡ Embedding æ¨¡å‹è®¡ç®— answer å’Œ ground_truth çš„ä½™å¼¦ç›¸ä¼¼åº¦
    2. äº‹å®å‡†ç¡®åº¦ï¼š
       - ç”¨ LLM å°† answer å’Œ ground_truth åˆ†åˆ«æå–ä¸ºè§‚ç‚¹åˆ—è¡¨
       - é€ä¸€å¯¹æ¯”è§‚ç‚¹ï¼Œåˆ¤æ–­æ˜¯å¦åŒ¹é…
         * éå† answer è§‚ç‚¹ï¼šèƒ½åœ¨ ground_truth ä¸­æ‰¾åˆ° â†’ TPï¼Œæ‰¾ä¸åˆ° â†’ FP
         * éå† ground_truth è§‚ç‚¹ï¼šåœ¨ answer ä¸­æ‰¾ä¸åˆ° â†’ FN
       - è®¡ç®— F1 Score = TP / (TP + 0.5*FP + 0.5*FN)
    3. ç»¼åˆå¾—åˆ† = 0.25 * è¯­ä¹‰ç›¸ä¼¼åº¦ + 0.75 * äº‹å®å‡†ç¡®åº¦
    
    ã€å…³é”®å‘ç°ã€‘
    - ä¸åŒå›ç­”çš„å¾—åˆ†å·®å¼‚æ˜æ˜¾
    - Ragas èƒ½å®¢è§‚é‡åŒ–å›ç­”è´¨é‡
    """
    print("\n" + "="*60)
    print("  æ­¥éª¤ 2: åˆè¯† Ragas æ¡†æ¶ - ç”Ÿæˆè´¨é‡è¯„ä¼°")
    print("="*60)

    from langchain_community.llms.tongyi import Tongyi
    from langchain_community.embeddings import DashScopeEmbeddings
    from datasets import Dataset
    from ragas import evaluate
    from ragas.metrics import answer_correctness

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    data_samples = {
        'question': [
            'å¼ ä¼Ÿæ˜¯å“ªä¸ªéƒ¨é—¨çš„ï¼Ÿ',
            'å¼ ä¼Ÿæ˜¯å“ªä¸ªéƒ¨é—¨çš„ï¼Ÿ',
            'å¼ ä¼Ÿæ˜¯å“ªä¸ªéƒ¨é—¨çš„ï¼Ÿ'
        ],
        'answer': [
            'æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ²¡æœ‰æåˆ°å¼ ä¼Ÿæ‰€åœ¨çš„éƒ¨é—¨ã€‚å¦‚æœæ‚¨èƒ½æä¾›æ›´å¤šå…³äºå¼ ä¼Ÿçš„ä¿¡æ¯ï¼Œæˆ‘å¯èƒ½èƒ½å¤Ÿå¸®åŠ©æ‚¨æ‰¾åˆ°ç­”æ¡ˆã€‚',
            'å¼ ä¼Ÿæ˜¯äººäº‹éƒ¨é—¨çš„',
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„'
        ],
        'ground_truth': [
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜',
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜',
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜'
        ]
    }

    print("\nğŸ“‹ æµ‹è¯•æ•°æ®ï¼š3 ä¸ªä¸åŒè´¨é‡çš„å›ç­”")
    for i in range(3):
        print(f"\næ ·æœ¬ {i+1}:")
        print(f"  å›ç­”: {data_samples['answer'][i][:50]}...")
        print(f"  æ­£ç¡®ç­”æ¡ˆ: {data_samples['ground_truth'][i]}")
    
    # åˆ›å»ºæ•°æ®é›†å¹¶è¯„ä¼°
    dataset = Dataset.from_dict(data_samples)
    
    print("\nğŸ” æ­£åœ¨ä½¿ç”¨ Ragas è¯„ä¼°...")
    score = evaluate(
        dataset=dataset,
        metrics=[answer_correctness],
        llm=Tongyi(model_name="qwen-plus"),
        embeddings=DashScopeEmbeddings(model="text-embedding-v3")
    )
    
    result = score.to_pandas()
    print("\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(result[['answer_correctness']].to_string(index=False))
    
    print("\nğŸ’¡ è§‚å¯Ÿï¼šå®Œå…¨æ­£ç¡®çš„å›ç­”å¾—åˆ†æœ€é«˜ï¼Œé”™è¯¯æˆ–å«ç³Šçš„å›ç­”å¾—åˆ†è¾ƒä½ã€‚")


# ==============================================================================
# æ­¥éª¤ 3: è¿›é˜¶ Ragas è¯„ä¼° - æ£€ç´¢è´¨é‡è¯„ä¼°
# ==============================================================================

def demo_ragas_retrieval_quality():
    """
    æ¼”ç¤º Ragas æ¡†æ¶çš„ Context Recall å’Œ Context Precision æŒ‡æ ‡ã€‚
    
    ã€æ ¸å¿ƒæ€æƒ³ã€‘
    è¯„ä¼° RAG ç³»ç»Ÿçš„æ£€ç´¢ç¯èŠ‚ï¼šä¸ä»…è¦"æ‰¾å¾—åˆ°"ï¼Œè¿˜è¦"æ’å¾—å‡†"ã€‚
    
    ã€Context Recall è®¡ç®—åŸç†ã€‘
    æè¿° ground_truth ä¸­æ¯ä¸ªè§‚ç‚¹åœ¨ contexts ä¸­è¢«æ£€ç´¢åˆ°çš„æ¯”ä¾‹ã€‚
    1. ç”¨ LLM å°† ground_truth æå–ä¸ºè§‚ç‚¹åˆ—è¡¨ï¼ˆä½œä¸ºåˆ†æ¯ï¼‰
    2. ç”¨ LLM åˆ¤æ–­æ¯ä¸ªè§‚ç‚¹æ˜¯å¦èƒ½åœ¨ contexts ä¸­æ‰¾åˆ°ï¼ˆæ‰¾åˆ°åˆ™åˆ†å­+1ï¼‰
    3. Context Recall = åˆ†å­ / åˆ†æ¯
    
    ã€Context Precision è®¡ç®—åŸç†ã€‘
    è¯„ä¼° contexts ä¸­ç›¸å…³ä¿¡æ¯çš„å æ¯”å’Œæ’åºè´¨é‡ï¼ˆAverage Precision@Kï¼‰ã€‚
    1. ç”¨ LLM é¡ºåºéå† context åˆ—è¡¨ï¼Œåˆ¤æ–­æ¯ä¸€é¡¹æ˜¯å¦ä¸ ground_truth ç›¸å…³
    2. å¯¹äºæ¯ä¸ª**ç›¸å…³**çš„ contextï¼ˆç¬¬ k é¡¹ï¼‰ï¼Œè®¡ç®— Precision@k = (å‰ké¡¹ä¸­ç›¸å…³é¡¹æ•°) / k
    3. Context Precision = æ‰€æœ‰ç›¸å…³é¡¹çš„ Precision@k ä¹‹å’Œ / ç›¸å…³é¡¹æ€»æ•°
    
    ã€æ¡ˆä¾‹è§£æã€‘
    åºåˆ— [ä¸ç›¸å…³, ç›¸å…³, ç›¸å…³]ï¼š
    - k=1 ä¸ç›¸å…³ï¼Œè·³è¿‡
    - k=2 ç›¸å…³ï¼ŒPrecision@2 = 1/2
    - k=3 ç›¸å…³ï¼ŒPrecision@3 = 2/3
    - Context Precision = (1/2 + 2/3) / 2 â‰ˆ 0.583
    
    ã€å…³é”®å‘ç°ã€‘
    - Context Recall çœ‹"æ‰¾æ²¡æ‰¾åˆ°"
    - Context Precision çœ‹"æ’åœ¨å“ªé‡Œ"
    - ä¸¤è€…ç»“åˆæ‰èƒ½å…¨é¢è¯„ä¼°æ£€ç´¢è´¨é‡
    """
    print("\n" + "="*60)
    print("  æ­¥éª¤ 3: è¿›é˜¶ Ragas è¯„ä¼° - æ£€ç´¢è´¨é‡è¯„ä¼°")
    print("="*60)

    from langchain_community.llms.tongyi import Tongyi
    from datasets import Dataset
    from ragas import evaluate
    from ragas.metrics import context_recall, context_precision

    # å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆåŒ…å« contextsï¼‰
    data_samples = {
        'question': [
            'å¼ ä¼Ÿæ˜¯å“ªä¸ªéƒ¨é—¨çš„ï¼Ÿ',
            'å¼ ä¼Ÿæ˜¯å“ªä¸ªéƒ¨é—¨çš„ï¼Ÿ',
            'å¼ ä¼Ÿæ˜¯å“ªä¸ªéƒ¨é—¨çš„ï¼Ÿ'
        ],
        'answer': [
            'æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ²¡æœ‰æåˆ°å¼ ä¼Ÿæ‰€åœ¨çš„éƒ¨é—¨ã€‚å¦‚æœæ‚¨èƒ½æä¾›æ›´å¤šå…³äºå¼ ä¼Ÿçš„ä¿¡æ¯ï¼Œæˆ‘å¯èƒ½èƒ½å¤Ÿå¸®åŠ©æ‚¨æ‰¾åˆ°ç­”æ¡ˆã€‚',
            'å¼ ä¼Ÿæ˜¯äººäº‹éƒ¨é—¨çš„',
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„'
        ],
        'ground_truth': [
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜',
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜',
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜'
        ],
        'contexts': [
            ['æä¾›â¾æ”¿ç®¡ç†ä¸åè°ƒâ½€æŒï¼Œä¼˜åŒ–â¾æ”¿â¼¯ä½œæµç¨‹ã€‚', 'ç»©æ•ˆç®¡ç†éƒ¨ éŸ©æ‰ æâ»œ I902 041 â¼ˆâ¼’èµ„æº'],
            ['æå‡¯ æ•™ç ”éƒ¨ä¸»ä»»', 'ç‰›é¡¿å‘ç°äº†ä¸‡æœ‰å¼•åŠ›'],
            ['ç‰›é¡¿å‘ç°äº†ä¸‡æœ‰å¼•åŠ›', 'å¼ ä¼Ÿ æ•™ç ”éƒ¨å·¥ç¨‹å¸ˆï¼Œä»–æœ€è¿‘åœ¨è´Ÿè´£è¯¾ç¨‹ç ”å‘'],
        ],
    }

    print("\nğŸ“‹ æµ‹è¯•æ•°æ®ï¼š3 ç»„ä¸åŒè´¨é‡çš„æ£€ç´¢ç»“æœ")
    for i in range(3):
        print(f"\næ ·æœ¬ {i+1}:")
        print(f"  Contexts: {data_samples['contexts'][i]}")
    
    # åˆ›å»ºæ•°æ®é›†å¹¶è¯„ä¼°
    dataset = Dataset.from_dict(data_samples)
    
    print("\nğŸ” æ­£åœ¨ä½¿ç”¨ Ragas è¯„ä¼°...")
    score = evaluate(
        dataset=dataset,
        metrics=[context_recall, context_precision],
        llm=Tongyi(model_name="qwen-plus")
    )
    
    result = score.to_pandas()
    print("\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(result[['context_recall', 'context_precision']].to_string(index=False))
    
    print("\nğŸ’¡ è§‚å¯Ÿï¼šæ ·æœ¬3çš„ Context Precision æ˜¯ 0.5ï¼Œå› ä¸ºç›¸å…³ä¿¡æ¯æ’åœ¨ç¬¬2ä½ã€‚")


# ==============================================================================
# æ­¥éª¤ 4: åŸç†æ·±åº¦è§£æ - Context Precision æ¡ˆä¾‹
# ==============================================================================

def demo_context_precision_case_study():
    """
    é€šè¿‡å…·ä½“æ¡ˆä¾‹æ·±åº¦è§£æ Context Precision çš„è®¡ç®—é€»è¾‘ã€‚
    
    ã€æ¡ˆä¾‹ã€‘
    Ground Truth: å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„
    Contexts: ["ç‰›é¡¿å‘ç°äº†ä¸‡æœ‰å¼•åŠ›", "å¼ ä¼Ÿ æ•™ç ”éƒ¨å·¥ç¨‹å¸ˆï¼Œä»–æœ€è¿‘åœ¨è´Ÿè´£è¯¾ç¨‹ç ”å‘"]
    
    ã€è®¡ç®—è¿‡ç¨‹ã€‘
    1. ç¬¬ä¸€é¡¹ "ç‰›é¡¿..." â†’ ä¸ç›¸å…³ (0)
    2. ç¬¬äºŒé¡¹ "å¼ ä¼Ÿ..." â†’ ç›¸å…³ (1)
       - æ­¤æ—¶æ£€ç´¢åˆ°äº†ç¬¬ 2 ä¸ªä½ç½® (k=2)
       - åœ¨å‰ 2 ä¸ªç»“æœä¸­ï¼Œæœ‰ 1 ä¸ªæ˜¯ç›¸å…³çš„
       - Precision@2 = 1/2 = 0.5
    
    Context Precision = Sum(Precision@K) / æ€»ç›¸å…³æ•°
                       = 0.5 / 1
                       = 0.5
    
    ã€å…³é”®å¯ç¤ºã€‘
    Context Precision ä¸ä»…çœ‹"æœ‰æ²¡æœ‰"ï¼Œè¿˜çœ‹"æ’åœ¨å“ª"ã€‚
    - å¦‚æœæŠŠ"å¼ ä¼Ÿ"æ’åœ¨ç¬¬ä¸€ä½ï¼Œåˆ†æ•°å°±æ˜¯ 1.0
    - è¿™è¿«ä½¿æˆ‘ä»¬åœ¨ RAG ä¸­ä¸ä»…è¦åšå¥½å¬å›ï¼Œè¿˜è¦åšå¥½é‡æ’åº (Rerank)
    
    ã€å®æˆ˜å»ºè®®ã€‘
    1. ä½¿ç”¨è¯­ä¹‰æ£€ç´¢æå‡å¬å›ç‡
    2. å¼•å…¥ Rerank æ¨¡å‹ä¼˜åŒ–æ’åº
    3. æŒç»­ç›‘æ§ Context Precision æŒ‡æ ‡
    """
    print("\n" + "="*60)
    print("  æ­¥éª¤ 4: åŸç†æ·±åº¦è§£æ - Context Precision æ¡ˆä¾‹")
    print("="*60)
    
    print("\nğŸ“š æ¡ˆä¾‹åˆ†æï¼šä¸ºä½•ç¬¬ä¸‰ç»„ Context Precision æ˜¯ 0.5ï¼Ÿ")
    print("-"*60)
    print("Ground Truth: å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„")
    print("Contexts: ['ç‰›é¡¿...', 'å¼ ä¼Ÿ...']")
    print()
    print("è®¡ç®—è¿‡ç¨‹ï¼š")
    print("  1. ç¬¬ä¸€é¡¹ 'ç‰›é¡¿...' â†’ ä¸ç›¸å…³ (0)")
    print("  2. ç¬¬äºŒé¡¹ 'å¼ ä¼Ÿ...' â†’ ç›¸å…³ (1)")
    print("     - æ­¤æ—¶æ£€ç´¢åˆ°äº†ç¬¬ 2 ä¸ªä½ç½® (k=2)")
    print("     - åœ¨å‰ 2 ä¸ªç»“æœä¸­ï¼Œæœ‰ 1 ä¸ªæ˜¯ç›¸å…³çš„")
    print("     - Precision@2 = 1/2 = 0.5")
    print()
    print("Context Precision = 0.5 / 1 = 0.5")
    print("-"*60)
    
    print("\nğŸ’¡ å…³é”®å¯ç¤ºï¼š")
    print("  âœ“ Context Precision ä¸ä»…çœ‹'æœ‰æ²¡æœ‰'ï¼Œè¿˜çœ‹'æ’åœ¨å“ª'")
    print("  âœ“ å¦‚æœæŠŠ'å¼ ä¼Ÿ'æ’åœ¨ç¬¬ä¸€ä½ï¼Œåˆ†æ•°å°±æ˜¯ 1.0")
    print("  âœ“ è¿™è¿«ä½¿æˆ‘ä»¬åšå¥½é‡æ’åº (Rerank)")


# ==============================================================================
# æ­¥éª¤ 5: ç”Ÿäº§çº§ä¼˜åŒ– - ä¸­æ–‡é€‚é…
# ==============================================================================

def demo_chinese_adaptation():
    """
    æ¼”ç¤ºä¸­æ–‡åœºæ™¯ä¸‹çš„ Ragas è¯„ä¼°ä¼˜åŒ–ã€‚
    
    ã€æ ¸å¿ƒé—®é¢˜ã€‘
    Ragas é»˜è®¤ä½¿ç”¨è‹±æ–‡ Promptï¼Œåœ¨ä¸­æ–‡åœºæ™¯ä¸‹æ•ˆæœä¸ä½³ã€‚
    
    ã€è§£å†³æ–¹æ¡ˆã€‘
    ä½¿ç”¨è‡ªå®šä¹‰çš„ä¸­æ–‡ Prompt æ¨¡æ¿æ›¿æ¢é»˜è®¤æ¨¡æ¿ã€‚
    
    ã€å®æ–½æ­¥éª¤ã€‘
    1. å¯¼å…¥ä¸­æ–‡æç¤ºè¯æ¨¡æ¿
    2. æ›¿æ¢å„æŒ‡æ ‡çš„ instructionã€output_formatã€examples
    3. é‡æ–°æ‰§è¡Œå…¨ç»´åº¦è¯„ä¼°
    
    ã€å…³é”®æ”¹è¿›ã€‘
    - æ›´å‡†ç¡®çš„ä¸­æ–‡è¯­ä¹‰ç†è§£
    - æ›´ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯çš„è¯„ä¼°æ ‡å‡†
    - æ›´ç¨³å®šçš„è¯„ä¼°ç»“æœ
    """
    print("\n" + "="*60)
    print("  æ­¥éª¤ 5: ç”Ÿäº§çº§ä¼˜åŒ– - ä¸­æ–‡é€‚é…")
    print("="*60)
    
    from langchain_community.llms.tongyi import Tongyi
    from langchain_community.embeddings import DashScopeEmbeddings
    from datasets import Dataset
    from ragas import evaluate
    from ragas.metrics import answer_correctness, context_recall, context_precision

# å¯¼å…¥ä¸­æ–‡æç¤ºè¯æ¨¡æ¿
    from ragas_prompt.chinese_prompt import (
        ContextRecall, ContextPrecision, AnswerCorrectness
    )
    
    print("\nğŸ”§ æ­£åœ¨åº”ç”¨ä¸­æ–‡ Prompt æ¨¡æ¿...")

    # è¿›è¡Œå„æŒ‡æ ‡çš„è‡ªå®šä¹‰ prompt è®¾ç½®
    context_recall.context_recall_prompt.instruction = (
        ContextRecall.context_recall_prompt["instruction"]
    )
    context_recall.context_recall_prompt.output_format_instruction = (
        ContextRecall.context_recall_prompt["output_format_instruction"]
    )
    context_recall.context_recall_prompt.examples = (
        ContextRecall.context_recall_prompt["examples"]
    )

    context_precision.context_precision_prompt.instruction = (
        ContextPrecision.context_precision_prompt["instruction"]
    )
    context_precision.context_precision_prompt.output_format_instruction = (
        ContextPrecision.context_precision_prompt["output_format_instruction"]
    )
    context_precision.context_precision_prompt.examples = (
        ContextPrecision.context_precision_prompt["examples"]
    )

    answer_correctness.correctness_prompt.instruction = (
        AnswerCorrectness.correctness_prompt["instruction"]
    )
    answer_correctness.correctness_prompt.output_format_instruction = (
        AnswerCorrectness.correctness_prompt["output_format_instruction"]
    )
    answer_correctness.correctness_prompt.examples = (
        AnswerCorrectness.correctness_prompt["examples"]
    )
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    data_samples = {
        'question': [
            'å¼ ä¼Ÿæ˜¯å“ªä¸ªéƒ¨é—¨çš„ï¼Ÿ',
            'å¼ ä¼Ÿæ˜¯å“ªä¸ªéƒ¨é—¨çš„ï¼Ÿ',
            'å¼ ä¼Ÿæ˜¯å“ªä¸ªéƒ¨é—¨çš„ï¼Ÿ'
        ],
        'answer': [
            'æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ²¡æœ‰æåˆ°å¼ ä¼Ÿæ‰€åœ¨çš„éƒ¨é—¨ã€‚å¦‚æœæ‚¨èƒ½æä¾›æ›´å¤šå…³äºå¼ ä¼Ÿçš„ä¿¡æ¯ï¼Œæˆ‘å¯èƒ½èƒ½å¤Ÿå¸®åŠ©æ‚¨æ‰¾åˆ°ç­”æ¡ˆã€‚',
            'å¼ ä¼Ÿæ˜¯äººäº‹éƒ¨é—¨çš„',
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„'
        ],
        'ground_truth': [
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜',
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜',
            'å¼ ä¼Ÿæ˜¯æ•™ç ”éƒ¨çš„æˆå‘˜'
        ],
        'contexts': [
            ['æä¾›â¾æ”¿ç®¡ç†ä¸åè°ƒâ½€æŒï¼Œä¼˜åŒ–â¾æ”¿â¼¯ä½œæµç¨‹ã€‚', 'ç»©æ•ˆç®¡ç†éƒ¨ éŸ©æ‰ æâ»œ I902 041 â¼ˆâ¼’èµ„æº'],
            ['æå‡¯ æ•™ç ”éƒ¨ä¸»ä»»', 'ç‰›é¡¿å‘ç°äº†ä¸‡æœ‰å¼•åŠ›'],
            ['ç‰›é¡¿å‘ç°äº†ä¸‡æœ‰å¼•åŠ›', 'å¼ ä¼Ÿ æ•™ç ”éƒ¨å·¥ç¨‹å¸ˆï¼Œä»–æœ€è¿‘åœ¨è´Ÿè´£è¯¾ç¨‹ç ”å‘'],
        ],
    }

    # åˆ›å»ºæ•°æ®é›†å¹¶è¯„ä¼°
    dataset = Dataset.from_dict(data_samples)

    print("ğŸ” æ­£åœ¨æ‰§è¡Œå…¨ç»´åº¦è¯„ä¼°ï¼ˆAnswer + Contextï¼‰...")
    score = evaluate(
        dataset=dataset,
        metrics=[answer_correctness, context_recall, context_precision],
        llm=Tongyi(model_name="qwen-plus"),
        embeddings=DashScopeEmbeddings(model="text-embedding-v3")
    )

    result = score.to_pandas()
    print("\nğŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æœï¼ˆä¸­æ–‡é€‚é…ï¼‰:")
    print(result[['answer_correctness', 'context_recall', 'context_precision']].to_string(index=False))
    
    print("\nğŸ’¡ è§‚å¯Ÿï¼šä½¿ç”¨ä¸­æ–‡ Prompt åï¼Œè¯„ä¼°ç»“æœæ›´åŠ å‡†ç¡®å’Œç¨³å®šã€‚")


# ==============================================================================
# ä¸»ç¨‹åºå…¥å£
# ==============================================================================

def main():
    """ä¸»ç¨‹åºï¼šæ‰§è¡Œæ‰€æœ‰ RAG è¯„ä¼°å®éªŒ"""
    
    print("\n" + "="*60)
    print("  RAG ç³»ç»Ÿè‡ªåŠ¨åŒ–è¯„ä¼° (Ragas)")
    print("="*60)
    
    # åŠ è½½ API Key
    load_key()
    
    try:
        # æ­¥éª¤ 1ï¼šæ‰‹åŠ¨ RAG è¯„ä¼°ä½“éªŒ
        demo_manual_rag_evaluation()
        
        # æ­¥éª¤ 2ï¼šåˆè¯† Ragas æ¡†æ¶ - ç”Ÿæˆè´¨é‡
        demo_ragas_answer_correctness()
        
        # æ­¥éª¤ 3ï¼šè¿›é˜¶ Ragas è¯„ä¼° - æ£€ç´¢è´¨é‡
        demo_ragas_retrieval_quality()
        
        # æ­¥éª¤ 4ï¼šåŸç†æ·±åº¦è§£æ
        demo_context_precision_case_study()
        
        # æ­¥éª¤ 5ï¼šç”Ÿäº§çº§ä¼˜åŒ– - ä¸­æ–‡é€‚é…
        demo_chinese_adaptation()
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*60)
    print("  æ‰€æœ‰å®éªŒå®Œæˆï¼")
    print("="*60)
    print("\nã€æ€»ç»“ã€‘")
    print("é€šè¿‡ Ragas æ¡†æ¶ï¼Œæˆ‘ä»¬å®ç°äº† RAG ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–ã€é‡åŒ–è¯„ä¼°ã€‚")
    print("\nã€å…³é”®è¦ç‚¹ã€‘")
    print("  âœ“ Answer Correctness: è¯„ä¼°å›ç­”çš„æ­£ç¡®æ€§ï¼ˆè¯­ä¹‰ + äº‹å®ï¼‰")
    print("  âœ“ Context Recall: è¯„ä¼°æ£€ç´¢çš„å¬å›ç‡ï¼ˆæ‰¾æ²¡æ‰¾åˆ°ï¼‰")
    print("  âœ“ Context Precision: è¯„ä¼°æ£€ç´¢çš„ç²¾ç¡®åº¦ï¼ˆæ’åœ¨å“ªé‡Œï¼‰")
    print("  âœ“ ä¸­æ–‡é€‚é…: ä½¿ç”¨è‡ªå®šä¹‰ Prompt æå‡è¯„ä¼°å‡†ç¡®æ€§")
    print("\nã€ä¸‹ä¸€æ­¥ã€‘")
    print("  â†’ å»ºç«‹è¯„ä¼°æ•°æ®é›†ï¼ŒæŒç»­ç›‘æ§ RAG è´¨é‡")
    print("  â†’ æ ¹æ®è¯„ä¼°ç»“æœï¼Œé’ˆå¯¹æ€§ä¼˜åŒ–æ£€ç´¢å’Œç”Ÿæˆç¯èŠ‚")
    print("  â†’ é›†æˆåˆ° CI/CDï¼Œç¡®ä¿æ¯æ¬¡æ”¹åŠ¨ä¸é™ä½è´¨é‡\n")


if __name__ == "__main__":
    main()
