# ==============================================================================
# 说明：简单 RAG 应用示例 (Retrieval-Augmented Generation)
# ==============================================================================
# 基于 llama_index 构建向量索引，实现检索增强生成(RAG)问答系统。
#
# 【核心概念】
# RAG = 检索 (Retrieval) + 生成 (Generation)
# 通过从知识库中检索相关文档片段，为 LLM 提供上下文，提升回答质量。
#
# 【本文件演示内容】
# 1. 知识库索引加载与查询
#    - 向量化文档并构建索引
#    - 基于相似度检索相关文档
#
# 2. Prompt 工程技巧
#    - 简单指令补丁（快速但不够稳定）
#    - 自定义 Prompt 模板（结构化、可控）
#    - 输出格式约束（JSON）
#    - Few-shot 样本引导（提供示例）
#    - Chain-of-Thought (COT) 思维链提示（引导推理）
#
# 【生产环境改进方向】
# - 向量存储: 替换为 Faiss/Milvus 等专业向量数据库（支持分布式、高并发）
# - 检索优化: 添加 Rerank 重排序提升召回质量（如 Cross-Encoder）
# - 架构分离: 索引服务与查询服务解耦（微服务化）
# - 性能优化: 引入 Redis 缓存层、支持增量索引更新
# - 评测体系: 建立 Retrieval Precision/Recall 和 Answer Quality 评测
# ==============================================================================

from chatbot import rag
from config.load_key import load_key


# ==============================================================================
# 辅助函数：提问接口
# ==============================================================================

def ask_llm(question, query_engine):
    """
    向 RAG 系统提问并打印流式响应。
    
    Args:
        question: 用户问题
        query_engine: LlamaIndex 查询引擎
    """
    print(f"\n💬 用户提问: {question}\n")
    print("🤖 AI 回答: ", end="")
    streaming_response = query_engine.query(question)
    streaming_response.print_response_stream()
    print("\n" + "-"*60)


# ==============================================================================
# 示例 1: 基础 RAG 查询 + 简单指令补丁
# ==============================================================================

def demo_basic_rag_with_instruction_patch(query_engine):
    """
    演示最简单的 RAG 查询和"指令补丁"技巧。
    
    【核心思想】
    通过在问题后直接追加指令，引导模型输出特定格式或内容。
    
    【优点】
    - 快速、简单，无需修改系统配置
    
    【缺点】
    - 不够稳定，容易被无关问题"误伤"
    - 缺乏结构化约束
    """
    print("\n" + "="*60)
    print("  示例 1: 基础 RAG 查询 + 简单指令补丁")
    print("="*60)
    
    # 场景 1：为工具推荐问题添加"附带官网链接"的指令
    print("\n【场景 1：工具推荐 + 指令补丁】")
    question = "我们公司项目管理应该用什么工具？"
    instruction = " 回答时请务必附带上工具的官方网站或下载链接。"
    new_question = question + instruction
    ask_llm(new_question, query_engine)

    # 场景 2：观察同样的指令在不相关问题上的表现
    print("\n【场景 2：年假查询 + 同样的指令补丁（观察效果）】")
    question_2 = "我们公司的年假有多少天？"
    instruction = " 回答时请务必附带上工具的官方网站或下载链接。"
    new_question_2 = question_2 + instruction
    ask_llm(new_question_2, query_engine)

    print("\n💡 观察：指令补丁虽然简单，但在无关场景下可能产生奇怪的输出。")


# ==============================================================================
# 示例 2: 自定义 Prompt 模板
# ==============================================================================

def demo_custom_prompt_template(query_engine):
    """
    演示如何通过自定义 Prompt 模板来规范 RAG 系统的行为。
    
    【核心思想】
    将系统角色、回答规范、上下文信息以结构化的方式组织到 Prompt 中。
    
    【对比原始模板】
    原始（LlamaIndex 默认）:
      Context information is below.
      ---------------------
      {context_str}
      ---------------------
      Given the context information and not prior knowledge, answer the query.
      Query: {query_str}
      Answer:
    
    自定义模板的改进：
    - 定义角色（客服小蜜）
    - 明确规范（简明扼要、依据上下文）
    - 结构清晰（注意事项 + 参考信息 + 问题）
    """
    print("\n" + "="*60)
    print("  示例 2: 自定义 Prompt 模板")
    print("="*60)
    
    # 构建自定义 Prompt 模板
    prompt_template_string = (
        "你是公司的客服小蜜，你需要简明扼要的回答用户的问题"
        "【注意事项】：\n"
        "1. 依据上下文信息来回答用户问题。\n"
        "2. 你只需要回答用户的问题，不要输出其他信息\n"
        "以下是参考信息。"
        "---------------------\n"
        "{context_str}\n"
        "---------------------\n"
        "问题：{query_str}\n。"
        "回答："
    )

    # 更新查询引擎的 Prompt 模板
    rag.update_prompt_template(query_engine, prompt_template_string)

    print("\n✅ Prompt 模板已更新")
    print("\n【测试：尝试让模型做不相关的任务】")
    question = """
把下列【】括起来的文本进行扩写和润色，让文案生动且富有创造力，并且受到公司新员工的喜欢。
【新员工训练营活动】
"""
    ask_llm(question, query_engine)
    
    print("\n💡 观察：通过 Prompt 模板，模型更倾向于拒绝不相关的请求，坚守'客服小蜜'的角色定位。")


# ==============================================================================
# 示例 3: 限制输出格式 (JSON)
# ==============================================================================

def demo_output_format_constraint(query_engine):
    """
    演示如何通过 Prompt 约束模型输出为特定格式（如 JSON）。
    
    【核心思想】
    在 Prompt 中明确规定输出格式和字段定义，强制模型遵守。
    
    【适用场景】
    - 需要结构化数据（便于后续处理）
    - API 返回值
    - 数据验证和清洗
    """
    print("\n" + "="*60)
    print("  示例 3: 限制输出格式 (JSON)")
    print("="*60)
    
    question_task = """
【任务要求】
你将看到一句话或一段话。你需要审查这段话中有没有错别字。如果出现了错别字，你要指出错误，并给出解释。
 "的" 和 "地" 混淆不算错别字，没有错误
---
【输出要求】
请你只输出json格式，不要输出代码段
其中，label只能取0或1，0代表有错误，1代表没有错误
reason是错误的原因
correct是修正后的文档内容
---
【用户输入】
以下是用户输入，请审阅：
"""
    question_doc = "分隔符是特殊的符号，它们帮助大语言模形 (LLM) 识别提示中哪些部分应当被视为一个完整的意思单元。"

    question = question_task + question_doc
    ask_llm(question, query_engine)

    print("\n💡 观察：模型识别出'模形'应为'模型'，并输出了符合要求的 JSON 格式。")


# ==============================================================================
# 示例 4: Few-shot 样本引导
# ==============================================================================

def demo_few_shot_learning(query_engine):
    """
    演示 Few-shot 提示技巧：通过提供示例来引导模型输出。
    
    【核心思想】
    "Show, don't tell" —— 与其描述要求，不如直接给出示例。
    
    【对比】
    - 错误方式：只描述要求（"以 Markdown 格式输出"）
    - 正确方式：提供完整示例 + 明确要求模仿风格
    """
    print("\n" + "="*60)
    print("  示例 4: Few-shot 样本引导")
    print("="*60)
    
    # 错误示例：只描述要求，没有提供样本
    print("\n【错误示例：只描述要求，无样本】")
    question_task_bad = """
【任务要求】
请你根据用户的主题，创作内容。
---
【输出要求】
最终输出需要以Markdown格式呈现，请注意，在你的回答中包含所有必要的Markdown元素，如标题、列表、链接、图片引用、加粗等，以便于阅读、后续编辑和保存。
---
【用户输入】
以下是用户的要求创作的主题：
"""
    question_doc_bad = "手工钥匙扣制作教程"
    question_bad = question_task_bad + question_doc_bad
    ask_llm(question_bad, query_engine)

    # 正确示例：提供完整样本，要求模仿
    print("\n【正确示例：提供完整样本并要求模仿】")
    question_task_good = """
【任务要求】
请根据用户的主题，结合下面【样例】给的例子，理解和使用一致的风格和结构继续创作内容，不要输出多余的内容。
---
【输出要求】
最终输出需要以Markdown格式呈现，请注意，在你的回答中包含所有必要的Markdown元素，如标题、列表、链接、图片引用、加粗等，以便于阅读、后续编辑和保存。
---
【样例】
### 示例1: 制作简易书签
# 简易书签制作教程

## 材料清单
- 彩色卡纸
- 剪刀
- 装饰贴纸
- 铅笔

## 步骤
1. 选择一张彩色卡纸。
2. 用铅笔在卡纸上画出一个长方形，尺寸约为2英寸 x 6英寸。
3. 沿着铅笔线剪下长方形。
4. 使用装饰贴纸对书签进行个性化装饰。
5. 完成！现在你有了一个独一无二的书签。

## 结束语
希望这个教程能帮助你制作出满意的书签！

---
【用户输入】
以下是用户的要求创作的主题：
"""
    question_doc_good = "制作手工贺卡"
    question_good = question_task_good + question_doc_good
    ask_llm(question_good, query_engine)
    
    print("\n💡 观察：提供样本后，模型能更准确地复制期望的输出结构和风格。")


# ==============================================================================
# 示例 5: Chain-of-Thought (COT) 思维链提示
# ==============================================================================

def demo_chain_of_thought(query_engine):
    """
    演示 COT 提示技巧：引导模型逐步推理，而非直接给出答案。
    
    【核心思想】
    让模型"显式地思考"，通过中间步骤来降低推理错误率。
    
    【对比】
    - 错误方式："直接给出总差旅费用，不要其他信息"（跳过推理）
    - 正确方式："请你一步步推导，计算总差旅费用"（引导推理）
    
    【适用场景】
    - 数学计算
    - 多步逻辑推理
    - 需要可解释性的决策
    """
    print("\n" + "="*60)
    print("  示例 5: Chain-of-Thought (COT) 思维链提示")
    print("="*60)
    
    # 错误示例：要求直接给答案
    print("\n【错误示例：要求直接给出答案，不要推理过程】")
    question_bad = """
【背景信息】
某教育培训机构（以下简称"公司"）在2023年度发生了以下主要支出：
为了给不同城市的学校学生上课，公司的老师全年共出差了5次，每次出差时间为一周，具体费用如下：
   - 交通费及住宿费：平均1600元/次
   - 教学用具采购费用：公司在年初一次性购买了一批教学用具，总价为10000元，预计可以使用4年。
   
【问题描述】
请根据上述背景信息，完成以下任务：
计算全年因教师出差而产生的差旅总费用，包括摊销的教学用具。

【输出要求】
直接给出总差旅费用，不要其他信息"""
    ask_llm(question_bad, query_engine)
    
    # 正确示例：要求逐步推导
    print("\n【正确示例：引导模型一步步推导】")
    question_good = """某教育培训机构（以下简称"公司"）在2023年度发生了以下主要支出：
为了给不同城市的学校学生上课，公司的老师全年共出差了5次，每次出差时间为一周，具体费用如下：
   - 交通费及住宿费：平均1600元/次
   - 教学用具采购费用：公司在年初一次性购买了一批教学用具，总价为10000元，预计可以使用4年。
   
### 问题描述
请根据上述背景信息，完成以下任务：
计算全年因教师出差而产生的差旅总费用，包括摊销的教学用具。

### 输出要求
请你一步步推导，计算总差旅费用"""
    ask_llm(question_good, query_engine)
    
    print("\n💡 观察：COT 提示让模型显式展示推理步骤，结果更可靠、可解释。")


# ==============================================================================
# 主程序入口
# ==============================================================================

def main():
    """主程序：初始化 RAG 系统并运行各个示例"""
    
    print("\n" + "="*60)
    print("  初始化 RAG 系统")
    print("="*60 + "\n")
    
    # 加载 API Key
    load_key()
    
    # 建立索引（如果尚未建立）
    print("📚 建立向量索引...")
    rag.indexing()
    
    # 加载索引（默认路径：knowledge_base/test）
    print("📂 加载向量索引...")
    index = rag.load_index()
    
    # 创建查询引擎
    print("🔧 创建查询引擎...")
    query_engine = rag.create_query_engine(index=index)
    
    print("✅ RAG 系统初始化完成！\n")
    
    # 运行各个演示示例
    try:
        # 示例 1：基础 RAG + 指令补丁
        demo_basic_rag_with_instruction_patch(query_engine)
        
        # 示例 2：自定义 Prompt 模板
        demo_custom_prompt_template(query_engine)
        
        # 示例 3：限制输出格式
        demo_output_format_constraint(query_engine)
        
        # 示例 4：Few-shot 样本引导
        demo_few_shot_learning(query_engine)
        
        # 示例 5：COT 思维链提示
        demo_chain_of_thought(query_engine)
        
    except Exception as e:
        print(f"\n❌ 运行出错: {e}")
    
    print("\n" + "="*60)
    print("  所有示例演示完成！")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()
